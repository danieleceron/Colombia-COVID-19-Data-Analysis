{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "033b0804d0c1459e906cf25915d39d6d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import unidecode\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "#geolocator = Nominatim(user_agent=\"https://nominatim.openstreetmap.org/\")\n",
    "geolocator = Nominatim(user_agent=\"https://maps.googleapis.com/\")\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID de caso    Fecha de notificación  Código DIVIPOLA  Ciudad de ubicación  \\\n0           1  2020-03-02T00:00:00.000            11001          Bogotá D.C.   \n1           2  2020-03-06T00:00:00.000            76111  Guadalajara de Buga   \n2           3  2020-03-07T00:00:00.000             5001             Medellín   \n3           4  2020-03-09T00:00:00.000             5001             Medellín   \n4           5  2020-03-09T00:00:00.000             5001             Medellín   \n\n  Departamento o Distrito     atención  Edad Sexo         Tipo Estado  \\\n0              Bogotá D.C.  Recuperado    19    F    Importado   Leve   \n1          Valle del Cauca  Recuperado    34    M    Importado   Leve   \n2                Antioquia  Recuperado    50    F    Importado   Leve   \n3                Antioquia  Recuperado    55    M  Relacionado   Leve   \n4                Antioquia  Recuperado    25    M  Relacionado   Leve   \n\n  País de procedencia                      FIS Fecha de muerte  \\\n0              ITALIA  2020-02-27T00:00:00.000             NaN   \n1              ESPAÑA  2020-03-04T00:00:00.000             NaN   \n2              ESPAÑA  2020-02-29T00:00:00.000             NaN   \n3                 NaN  2020-03-06T00:00:00.000             NaN   \n4                 NaN  2020-03-08T00:00:00.000             NaN   \n\n         Fecha diagnostico         Fecha recuperado        fecha reporte web  \\\n0  2020-03-06T00:00:00.000  2020-03-13T00:00:00.000  2020-03-06T00:00:00.000   \n1  2020-03-09T00:00:00.000  2020-03-19T00:00:00.000  2020-03-09T00:00:00.000   \n2  2020-03-09T00:00:00.000  2020-03-15T00:00:00.000  2020-03-09T00:00:00.000   \n3  2020-03-11T00:00:00.000  2020-03-26T00:00:00.000  2020-03-11T00:00:00.000   \n4  2020-03-11T00:00:00.000  2020-03-23T00:00:00.000  2020-03-11T00:00:00.000   \n\n  Tipo recuperación  Codigo departamento  Codigo pais Pertenencia etnica  \\\n0               PCR                   11        380.0               Otro   \n1               PCR                   76        724.0              Negro   \n2               PCR                    5        724.0               Otro   \n3               PCR                    5          NaN               Otro   \n4               PCR                    5          NaN               Otro   \n\n  Nombre grupo etnico  \n0                 NaN  \n1                 NaN  \n2                 NaN  \n3                 NaN  \n4                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID de caso</th>\n      <th>Fecha de notificación</th>\n      <th>Código DIVIPOLA</th>\n      <th>Ciudad de ubicación</th>\n      <th>Departamento o Distrito</th>\n      <th>atención</th>\n      <th>Edad</th>\n      <th>Sexo</th>\n      <th>Tipo</th>\n      <th>Estado</th>\n      <th>País de procedencia</th>\n      <th>FIS</th>\n      <th>Fecha de muerte</th>\n      <th>Fecha diagnostico</th>\n      <th>Fecha recuperado</th>\n      <th>fecha reporte web</th>\n      <th>Tipo recuperación</th>\n      <th>Codigo departamento</th>\n      <th>Codigo pais</th>\n      <th>Pertenencia etnica</th>\n      <th>Nombre grupo etnico</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-03-02T00:00:00.000</td>\n      <td>11001</td>\n      <td>Bogotá D.C.</td>\n      <td>Bogotá D.C.</td>\n      <td>Recuperado</td>\n      <td>19</td>\n      <td>F</td>\n      <td>Importado</td>\n      <td>Leve</td>\n      <td>ITALIA</td>\n      <td>2020-02-27T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>2020-03-13T00:00:00.000</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>PCR</td>\n      <td>11</td>\n      <td>380.0</td>\n      <td>Otro</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>76111</td>\n      <td>Guadalajara de Buga</td>\n      <td>Valle del Cauca</td>\n      <td>Recuperado</td>\n      <td>34</td>\n      <td>M</td>\n      <td>Importado</td>\n      <td>Leve</td>\n      <td>ESPAÑA</td>\n      <td>2020-03-04T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-19T00:00:00.000</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>PCR</td>\n      <td>76</td>\n      <td>724.0</td>\n      <td>Negro</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2020-03-07T00:00:00.000</td>\n      <td>5001</td>\n      <td>Medellín</td>\n      <td>Antioquia</td>\n      <td>Recuperado</td>\n      <td>50</td>\n      <td>F</td>\n      <td>Importado</td>\n      <td>Leve</td>\n      <td>ESPAÑA</td>\n      <td>2020-02-29T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-15T00:00:00.000</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>724.0</td>\n      <td>Otro</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>5001</td>\n      <td>Medellín</td>\n      <td>Antioquia</td>\n      <td>Recuperado</td>\n      <td>55</td>\n      <td>M</td>\n      <td>Relacionado</td>\n      <td>Leve</td>\n      <td>NaN</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>2020-03-26T00:00:00.000</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>Otro</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>5001</td>\n      <td>Medellín</td>\n      <td>Antioquia</td>\n      <td>Recuperado</td>\n      <td>25</td>\n      <td>M</td>\n      <td>Relacionado</td>\n      <td>Leve</td>\n      <td>NaN</td>\n      <td>2020-03-08T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>2020-03-23T00:00:00.000</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>Otro</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#reading/storing and showing the Covid dataset of Colombia\n",
    "#df=pd.read_csv('Casos_positivos_de_COVID-19_en_Colombia.csv')\n",
    "#df=pd.read_csv('Covid18-09-20.csv')\n",
    "#df.to_pickle('Covid18-09-20.plk')\n",
    "\n",
    "df=pd.read_pickle('Covid18-09-20.plk')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(743945, 21)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#show the features and the len of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 22 different geatures and 357710 of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['ID de caso', 'Fecha de notificación', 'Código DIVIPOLA',\n       'Ciudad de ubicación', 'Departamento o Distrito ', 'atención', 'Edad',\n       'Sexo', 'Tipo', 'Estado', 'País de procedencia', 'FIS',\n       'Fecha de muerte', 'Fecha diagnostico', 'Fecha recuperado',\n       'fecha reporte web', 'Tipo recuperación', 'Codigo departamento',\n       'Codigo pais', 'Pertenencia etnica', 'Nombre grupo etnico'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#show the all the features (columns)\n",
    "df.columns"
   ]
  },
  {
   "source": [
    "Formating Columns headders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID DE CASO    FECHA DE NOTIFICACIÓN  CÓDIGO DIVIPOLA  CIUDAD DE UBICACIÓN  \\\n0           1  2020-03-02T00:00:00.000            11001          Bogotá D.C.   \n1           2  2020-03-06T00:00:00.000            76111  Guadalajara de Buga   \n\n  DEPARTAMENTO O DISTRITO     ATENCIÓN  EDAD SEXO       TIPO ESTADO  \\\n0              Bogotá D.C.  Recuperado    19    F  Importado   Leve   \n1          Valle del Cauca  Recuperado    34    M  Importado   Leve   \n\n  PAÍS DE PROCEDENCIA                      FIS FECHA DE MUERTE  \\\n0              ITALIA  2020-02-27T00:00:00.000             NaN   \n1              ESPAÑA  2020-03-04T00:00:00.000             NaN   \n\n         FECHA DIAGNOSTICO         FECHA RECUPERADO        FECHA REPORTE WEB  \\\n0  2020-03-06T00:00:00.000  2020-03-13T00:00:00.000  2020-03-06T00:00:00.000   \n1  2020-03-09T00:00:00.000  2020-03-19T00:00:00.000  2020-03-09T00:00:00.000   \n\n  TIPO RECUPERACIÓN  CODIGO DEPARTAMENTO  CODIGO PAIS PERTENENCIA ETNICA  \\\n0               PCR                   11        380.0               Otro   \n1               PCR                   76        724.0              Negro   \n\n  NOMBRE GRUPO ETNICO  \n0                 NaN  \n1                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID DE CASO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>CÓDIGO DIVIPOLA</th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>EDAD</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>CODIGO DEPARTAMENTO</th>\n      <th>CODIGO PAIS</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-03-02T00:00:00.000</td>\n      <td>11001</td>\n      <td>Bogotá D.C.</td>\n      <td>Bogotá D.C.</td>\n      <td>Recuperado</td>\n      <td>19</td>\n      <td>F</td>\n      <td>Importado</td>\n      <td>Leve</td>\n      <td>ITALIA</td>\n      <td>2020-02-27T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>2020-03-13T00:00:00.000</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>PCR</td>\n      <td>11</td>\n      <td>380.0</td>\n      <td>Otro</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>76111</td>\n      <td>Guadalajara de Buga</td>\n      <td>Valle del Cauca</td>\n      <td>Recuperado</td>\n      <td>34</td>\n      <td>M</td>\n      <td>Importado</td>\n      <td>Leve</td>\n      <td>ESPAÑA</td>\n      <td>2020-03-04T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-19T00:00:00.000</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>PCR</td>\n      <td>76</td>\n      <td>724.0</td>\n      <td>Negro</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.columns = df.columns.str.upper()\n",
    "#df.columns = map(str.upper, df.columns)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 743945 entries, 0 to 743944\nData columns (total 21 columns):\n #   Column                    Non-Null Count   Dtype  \n---  ------                    --------------   -----  \n 0   ID DE CASO                743945 non-null  int64  \n 1   FECHA DE NOTIFICACIÓN     743945 non-null  object \n 2   CÓDIGO DIVIPOLA           743945 non-null  int64  \n 3   CIUDAD DE UBICACIÓN       743945 non-null  object \n 4   DEPARTAMENTO O DISTRITO   743945 non-null  object \n 5   ATENCIÓN                  742389 non-null  object \n 6   EDAD                      743945 non-null  int64  \n 7   SEXO                      743945 non-null  object \n 8   TIPO                      743945 non-null  object \n 9   ESTADO                    742175 non-null  object \n 10  PAÍS DE PROCEDENCIA       968 non-null     object \n 11  FIS                       651137 non-null  object \n 12  FECHA DE MUERTE           25317 non-null   object \n 13  FECHA DIAGNOSTICO         739876 non-null  object \n 14  FECHA RECUPERADO          615457 non-null  object \n 15  FECHA REPORTE WEB         743945 non-null  object \n 16  TIPO RECUPERACIÓN         615457 non-null  object \n 17  CODIGO DEPARTAMENTO       743945 non-null  int64  \n 18  CODIGO PAIS               968 non-null     float64\n 19  PERTENENCIA ETNICA        694659 non-null  object \n 20  NOMBRE GRUPO ETNICO       12208 non-null   object \ndtypes: float64(1), int64(4), object(16)\nmemory usage: 73.8+ MB\n"
    }
   ],
   "source": [
    "# info() show a description indicating the values and type of each feature\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are some features with missing values and erratic dtypes, in order to fix that we need to look each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     FECHA DE NOTIFICACIÓN                      FIS FECHA DE MUERTE  \\\n0  2020-03-02T00:00:00.000  2020-02-27T00:00:00.000             NaN   \n1  2020-03-06T00:00:00.000  2020-03-04T00:00:00.000             NaN   \n2  2020-03-07T00:00:00.000  2020-02-29T00:00:00.000             NaN   \n3  2020-03-09T00:00:00.000  2020-03-06T00:00:00.000             NaN   \n4  2020-03-09T00:00:00.000  2020-03-08T00:00:00.000             NaN   \n\n         FECHA DIAGNOSTICO         FECHA RECUPERADO        FECHA REPORTE WEB  \n0  2020-03-06T00:00:00.000  2020-03-13T00:00:00.000  2020-03-06T00:00:00.000  \n1  2020-03-09T00:00:00.000  2020-03-19T00:00:00.000  2020-03-09T00:00:00.000  \n2  2020-03-09T00:00:00.000  2020-03-15T00:00:00.000  2020-03-09T00:00:00.000  \n3  2020-03-11T00:00:00.000  2020-03-26T00:00:00.000  2020-03-11T00:00:00.000  \n4  2020-03-11T00:00:00.000  2020-03-23T00:00:00.000  2020-03-11T00:00:00.000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-03-02T00:00:00.000</td>\n      <td>2020-02-27T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>2020-03-13T00:00:00.000</td>\n      <td>2020-03-06T00:00:00.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>2020-03-04T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-19T00:00:00.000</td>\n      <td>2020-03-09T00:00:00.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-03-07T00:00:00.000</td>\n      <td>2020-02-29T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-15T00:00:00.000</td>\n      <td>2020-03-09T00:00:00.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-06T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>2020-03-26T00:00:00.000</td>\n      <td>2020-03-11T00:00:00.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-03-09T00:00:00.000</td>\n      <td>2020-03-08T00:00:00.000</td>\n      <td>NaN</td>\n      <td>2020-03-11T00:00:00.000</td>\n      <td>2020-03-23T00:00:00.000</td>\n      <td>2020-03-11T00:00:00.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Looking the structure of the date features \n",
    "\n",
    "col_de_fechas=[col for col in df if col.startswith('F')]\n",
    "\n",
    "df[col_de_fechas].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each date feature have a T between the date and the time, so we need to remove the T and remove the time, as we only have 00:00:00:000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the following code remove the T from the dates features but also store the time in the unwanted column\n",
    "for fechas in col_de_fechas:\n",
    "    df[[fechas,'unwanted']]=df[fechas].str.split(pat=\"T\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  FECHA DE NOTIFICACIÓN         FIS FECHA DE MUERTE FECHA DIAGNOSTICO  \\\n0            2020-03-02  2020-02-27             NaN        2020-03-06   \n1            2020-03-06  2020-03-04             NaN        2020-03-09   \n2            2020-03-07  2020-02-29             NaN        2020-03-09   \n3            2020-03-09  2020-03-06             NaN        2020-03-11   \n4            2020-03-09  2020-03-08             NaN        2020-03-11   \n\n  FECHA RECUPERADO FECHA REPORTE WEB  \n0       2020-03-13        2020-03-06  \n1       2020-03-19        2020-03-09  \n2       2020-03-15        2020-03-09  \n3       2020-03-26        2020-03-11  \n4       2020-03-23        2020-03-11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-03-02</td>\n      <td>2020-02-27</td>\n      <td>NaN</td>\n      <td>2020-03-06</td>\n      <td>2020-03-13</td>\n      <td>2020-03-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-03-06</td>\n      <td>2020-03-04</td>\n      <td>NaN</td>\n      <td>2020-03-09</td>\n      <td>2020-03-19</td>\n      <td>2020-03-09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-03-07</td>\n      <td>2020-02-29</td>\n      <td>NaN</td>\n      <td>2020-03-09</td>\n      <td>2020-03-15</td>\n      <td>2020-03-09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-03-09</td>\n      <td>2020-03-06</td>\n      <td>NaN</td>\n      <td>2020-03-11</td>\n      <td>2020-03-26</td>\n      <td>2020-03-11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-03-09</td>\n      <td>2020-03-08</td>\n      <td>NaN</td>\n      <td>2020-03-11</td>\n      <td>2020-03-23</td>\n      <td>2020-03-11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df[col_de_fechas].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['00:00:00.000'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df['unwanted'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As unwanted does provide a useful time, we will get rid of that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the column unwanted and save the changes to the df (inplace=True)\n",
    "df.drop(columns=['unwanted'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform the dtype form objecto to a datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_de_fechas:\n",
    "    df[col]=df[col].apply(lambda x: pd.NaT if x=='ERROR: #N/A' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=743945.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b180486d2264c4dbfd66bbb73d37e65"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=743945.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe69bb5187e843d798146361fd538d2d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "#Create a new column called Asintomático FIS to store  the values of 'Asintomático' from FIS\n",
    "df['ASINTOMÁTICO FIS']=df['FIS'].progress_apply(lambda x: 'Asintomático' if x=='Asintomático' else np.nan)\n",
    "#Removing 'Asintomático' from FIS columns and convert to datetime\n",
    "df.FIS=df['FIS'].progress_apply(lambda x:  pd.NaT if x=='Asintomático' else pd.to_datetime(x,format='%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#if re.match(\"^[a-zA-Z]+.*\", line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fechas_to_date=['Fecha de notificación','Fecha de muerte', 'Fecha diagnostico', 'Fecha recuperado','fecha reporte web']\n",
    "\n",
    "for fechas in col_de_fechas:\n",
    "    df[fechas]= pd.to_datetime(df[fechas],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "FECHA DE NOTIFICACIÓN    datetime64[ns]\nFIS                      datetime64[ns]\nFECHA DE MUERTE          datetime64[ns]\nFECHA DIAGNOSTICO        datetime64[ns]\nFECHA RECUPERADO         datetime64[ns]\nFECHA REPORTE WEB        datetime64[ns]\ndtype: object"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df.select_dtypes(include='datetime').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Leve' 'Asintomático' 'Fallecido' nan 'Moderado' 'Grave']\n['Importado' 'Relacionado' 'En estudio' 'relacionado' 'RELACIONADO'\n 'En Estudio']\n['Recuperado' 'Fallecido' nan 'Casa' 'Hospital' 'Hospital UCI']\n"
    }
   ],
   "source": [
    "print(df.ESTADO.unique())\n",
    "print(df.TIPO.unique())\n",
    "print(df.ATENCIÓN.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some feature have duplicated values, so we goin to see me unique values for certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------\nID DE CASO\n743945\n------------------------------------------\nCÓDIGO DIVIPOLA\n1042\n------------------------------------------\nCIUDAD DE UBICACIÓN\n967\n------------------------------------------\nDEPARTAMENTO O DISTRITO \n37\n------------------------------------------\nATENCIÓN\n6\n------------------------------------------\nEDAD\n112\n------------------------------------------\nSEXO\n4\n------------------------------------------\nTIPO\n6\n------------------------------------------\nESTADO\n6\n------------------------------------------\nPAÍS DE PROCEDENCIA\n51\n------------------------------------------\nTIPO RECUPERACIÓN\n3\n------------------------------------------\nCODIGO DEPARTAMENTO\n33\n------------------------------------------\nCODIGO PAIS\n46\n------------------------------------------\nPERTENENCIA ETNICA\n5\n------------------------------------------\nNOMBRE GRUPO ETNICO\n744\n------------------------------------------\nASINTOMÁTICO FIS\n1\n"
    }
   ],
   "source": [
    "for columna in df.select_dtypes(exclude='datetime').columns:#.drop(['ID de caso','Código DIVIPOLA','Ciudad de ubicación'],axis=1).columns:\n",
    "    print('------------------------------------------')\n",
    "    print(columna)\n",
    "    print(len(df[columna].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fix duplicate values were are goin to  remove punctuation and only leave uppercase strings.\n",
    "For numeric values is a bit more difficult as we have codes for municipalities, but we can see the Edad (Age) feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bananá\n"
    }
   ],
   "source": [
    "#example of the strip function for str values\n",
    "txt = \",,,!!!,,r--rttgg...   ..bananá....__rrr\"\n",
    "x = txt.strip(\",.grt! -_\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Malaga'"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Example of how to remove accent\n",
    "accented_string = 'Málaga'\n",
    "# accented_string is of type 'unicode'\n",
    "import unidecode\n",
    "unidecode.unidecode(accented_string)\n",
    "# unaccented_string contains 'Malaga'and is of type 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'MALAGA'"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "unidecode.unidecode(accented_string.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables we'll change nan values to a 'No info' string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "10%|█         | 1/10 [00:15<02:22, 15.87s/it]Compleated feature: CIUDAD DE UBICACIÓN\n 20%|██        | 2/10 [00:30<02:03, 15.41s/it]Compleated feature: DEPARTAMENTO O DISTRITO \n 30%|███       | 3/10 [00:33<01:22, 11.79s/it]Compleated feature: ATENCIÓN\n 40%|████      | 4/10 [00:36<00:54,  9.14s/it]Compleated feature: SEXO\n 50%|█████     | 5/10 [00:39<00:37,  7.42s/it]Compleated feature: TIPO\n 60%|██████    | 6/10 [00:46<00:28,  7.03s/it]Compleated feature: ESTADO\n 70%|███████   | 7/10 [00:49<00:17,  5.88s/it]Compleated feature: PAÍS DE PROCEDENCIA\n 80%|████████  | 8/10 [00:52<00:10,  5.13s/it]Compleated feature: TIPO RECUPERACIÓN\n 90%|█████████ | 9/10 [00:56<00:04,  4.74s/it]Compleated feature: PERTENENCIA ETNICA\n100%|██████████| 10/10 [01:00<00:00,  6.02s/it]Compleated feature: NOMBRE GRUPO ETNICO\n\n"
    }
   ],
   "source": [
    "# Filling nan values, applying uppes case and remove accent for each value of each feature\n",
    "for feature in tqdm(df.select_dtypes(include=['object']).columns):\n",
    "    df[feature]=df[feature].fillna('No info')\n",
    "    df[feature]=df[feature].apply(lambda x: unidecode.unidecode(x.upper()))\n",
    "    print('Compleated feature: '+feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   CIUDAD DE UBICACIÓN DEPARTAMENTO O DISTRITO     ATENCIÓN SEXO         TIPO  \\\n0          BOGOTA D.C.              BOGOTA D.C.  RECUPERADO    F    IMPORTADO   \n1  GUADALAJARA DE BUGA          VALLE DEL CAUCA  RECUPERADO    M    IMPORTADO   \n2             MEDELLIN                ANTIOQUIA  RECUPERADO    F    IMPORTADO   \n3             MEDELLIN                ANTIOQUIA  RECUPERADO    M  RELACIONADO   \n4             MEDELLIN                ANTIOQUIA  RECUPERADO    M  RELACIONADO   \n\n  ESTADO PAÍS DE PROCEDENCIA TIPO RECUPERACIÓN PERTENENCIA ETNICA  \\\n0   LEVE              ITALIA               PCR               OTRO   \n1   LEVE              ESPANA               PCR              NEGRO   \n2   LEVE              ESPANA               PCR               OTRO   \n3   LEVE             NO INFO               PCR               OTRO   \n4   LEVE             NO INFO               PCR               OTRO   \n\n  NOMBRE GRUPO ETNICO  \n0             NO INFO  \n1             NO INFO  \n2             NO INFO  \n3             NO INFO  \n4             NO INFO  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BOGOTA D.C.</td>\n      <td>BOGOTA D.C.</td>\n      <td>RECUPERADO</td>\n      <td>F</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ITALIA</td>\n      <td>PCR</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GUADALAJARA DE BUGA</td>\n      <td>VALLE DEL CAUCA</td>\n      <td>RECUPERADO</td>\n      <td>M</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ESPANA</td>\n      <td>PCR</td>\n      <td>NEGRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>F</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ESPANA</td>\n      <td>PCR</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>LEVE</td>\n      <td>NO INFO</td>\n      <td>PCR</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>LEVE</td>\n      <td>NO INFO</td>\n      <td>PCR</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------\nID DE CASO\n743945\n------------------------------------------\nCÓDIGO DIVIPOLA\n1042\n------------------------------------------\nCIUDAD DE UBICACIÓN\n966\n------------------------------------------\nDEPARTAMENTO O DISTRITO \n37\n------------------------------------------\nATENCIÓN\n6\n------------------------------------------\nEDAD\n112\n------------------------------------------\nSEXO\n2\n------------------------------------------\nTIPO\n3\n------------------------------------------\nESTADO\n6\n------------------------------------------\nPAÍS DE PROCEDENCIA\n48\n------------------------------------------\nTIPO RECUPERACIÓN\n3\n------------------------------------------\nCODIGO DEPARTAMENTO\n33\n------------------------------------------\nCODIGO PAIS\n46\n------------------------------------------\nPERTENENCIA ETNICA\n5\n------------------------------------------\nNOMBRE GRUPO ETNICO\n716\n------------------------------------------\nASINTOMÁTICO FIS\n1\n"
    }
   ],
   "source": [
    "for columna in df.select_dtypes(exclude='datetime').columns:#.drop(['ID de caso','Código DIVIPOLA','Ciudad de ubicación'],axis=1).columns:\n",
    "    print('------------------------------------------')\n",
    "    print(columna)\n",
    "    print(len(df[columna].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     feature     len\n0                 ID DE CASO  743945\n1            CÓDIGO DIVIPOLA    1042\n2        CIUDAD DE UBICACIÓN     966\n3   DEPARTAMENTO O DISTRITO       37\n4                   ATENCIÓN       6\n5                       EDAD     112\n6                       SEXO       2\n7                       TIPO       3\n8                     ESTADO       6\n9        PAÍS DE PROCEDENCIA      48\n10         TIPO RECUPERACIÓN       3\n11       CODIGO DEPARTAMENTO      33\n12               CODIGO PAIS      46\n13        PERTENENCIA ETNICA       5\n14       NOMBRE GRUPO ETNICO     716\n15          ASINTOMÁTICO FIS       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID DE CASO</td>\n      <td>743945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CÓDIGO DIVIPOLA</td>\n      <td>1042</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CIUDAD DE UBICACIÓN</td>\n      <td>966</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DEPARTAMENTO O DISTRITO</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATENCIÓN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>EDAD</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SEXO</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>TIPO</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ESTADO</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PAÍS DE PROCEDENCIA</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>TIPO RECUPERACIÓN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>CODIGO DEPARTAMENTO</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>CODIGO PAIS</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PERTENENCIA ETNICA</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NOMBRE GRUPO ETNICO</td>\n      <td>716</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ASINTOMÁTICO FIS</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# same code as before but using list mprehension and converting it into a DataFrame\n",
    "pd.DataFrame([[p,len(df[p].unique())] for p in df.select_dtypes(exclude='datetime').columns],columns=['feature','len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that some of the values of the features reduce, bc duplicated values has been removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------\nATENCIÓN\n['RECUPERADO' 'FALLECIDO' 'NO INFO' 'CASA' 'HOSPITAL' 'HOSPITAL UCI']\n------------------------------------------\nSEXO\n['F' 'M']\n------------------------------------------\nTIPO\n['IMPORTADO' 'RELACIONADO' 'EN ESTUDIO']\n------------------------------------------\nESTADO\n['LEVE' 'ASINTOMATICO' 'FALLECIDO' 'NO INFO' 'MODERADO' 'GRAVE']\n------------------------------------------\nTIPO RECUPERACIÓN\n['PCR' 'TIEMPO' 'NO INFO']\n------------------------------------------\nPERTENENCIA ETNICA\n['OTRO' 'NEGRO' 'INDIGENA' 'ROM' 'NO INFO']\n------------------------------------------\nASINTOMÁTICO FIS\n[nan]\n"
    }
   ],
   "source": [
    "for columna in df.select_dtypes(exclude='datetime').drop(['ID DE CASO','CÓDIGO DIVIPOLA','CIUDAD DE UBICACIÓN'],axis=1).columns:\n",
    "    if len(df[columna].unique())<10:\n",
    "        print('------------------------------------------')\n",
    "        print(columna)\n",
    "        print(df[columna].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing to do is check if the ```atención values``` agrees with ```Estado```, and dates match , i.g.  we don't want  that feature 'Estado'='Fallecido' have a different value in the feature 'atención'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------\nATENCIÓN: RECUPERADO\nLEVE            537128\nASINTOMATICO     67653\nMODERADO          9221\nGRAVE             1162\nNO INFO            293\nName: ESTADO, dtype: int64\n------------------------\nATENCIÓN: FALLECIDO\nFALLECIDO    23665\nName: ESTADO, dtype: int64\n------------------------\nATENCIÓN: NO INFO\nNO INFO         1477\nASINTOMATICO      79\nName: ESTADO, dtype: int64\n------------------------\nATENCIÓN: CASA\nLEVE            63939\nASINTOMATICO    24684\nName: ESTADO, dtype: int64\n------------------------\nATENCIÓN: HOSPITAL\nMODERADO        13218\nASINTOMATICO      284\nName: ESTADO, dtype: int64\n------------------------\nATENCIÓN: HOSPITAL UCI\nGRAVE           1034\nASINTOMATICO     108\nName: ESTADO, dtype: int64\n"
    }
   ],
   "source": [
    "for atenticion in df['ATENCIÓN'].unique():\n",
    "    print('------------------------')\n",
    "    print('ATENCIÓN: '+atenticion)\n",
    "    print(df[df['ATENCIÓN']==atenticion]['ESTADO'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark for the unique values of  the feature Estado:\n",
    "\n",
    "* 'Recuperado' have LEVE, MODERADO, GRAVE, ASINTOMATICO and NO INFO. maybe that was the health condition of those  people.\n",
    "\n",
    "* 'Fallecido' seems good has it have no different values despite FALLECIIDO\n",
    "\n",
    "* 'HOSPITAL' only have MODERADO and ASINTOMATICO, for that las values his wird to have it in HOSPITAL.\n",
    "\n",
    "* 'HOSPITAL UCI' GRAVE seems good for that health condition BUT IT IS WEIRD TO THINK THAT ASINTOMATICO IS IN UCI.\n",
    "\n",
    "* 'NO INFO'  contains NO INFO and ASINTOMATICO\n",
    "\n",
    "* 'CASA' have LEVE and ASINTOMATICO, wich seems good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop  Estado= ASINTOMATICO where atención= HOSPITAL and atención=HOSPITAL UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(743945, 22)\n(743661, 22)\n(743837, 22)\n"
    }
   ],
   "source": [
    "#getting the index \n",
    "idx_h=df[(df['ESTADO']=='ASINTOMATICO') & (df['ATENCIÓN']=='HOSPITAL')].index\n",
    "idx_hu=df[(df['ESTADO']=='ASINTOMATICO') & (df['ATENCIÓN']=='HOSPITAL UCI')].index\n",
    "\n",
    "#printing the shape of the df when droping those indexes \n",
    "print(df.shape)\n",
    "print(df.drop(idx_h).shape)\n",
    "print(df.drop(idx_hu).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping those indexes in the data frame\n",
    "df.drop(idx_h,inplace=True)\n",
    "df.drop(idx_hu,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------\nATENCIÓN: RECUPERADO\nTIEMPO    510302\nPCR       105155\nName: TIPO RECUPERACIÓN, dtype: int64\n------------------------\nATENCIÓN: FALLECIDO\nNO INFO    23665\nName: TIPO RECUPERACIÓN, dtype: int64\n------------------------\nATENCIÓN: NO INFO\nNO INFO    1556\nName: TIPO RECUPERACIÓN, dtype: int64\n------------------------\nATENCIÓN: CASA\nNO INFO    88623\nName: TIPO RECUPERACIÓN, dtype: int64\n------------------------\nATENCIÓN: HOSPITAL\nNO INFO    13218\nName: TIPO RECUPERACIÓN, dtype: int64\n------------------------\nATENCIÓN: HOSPITAL UCI\nNO INFO    1034\nName: TIPO RECUPERACIÓN, dtype: int64\n"
    }
   ],
   "source": [
    "for atenticion in df['ATENCIÓN'].unique():\n",
    "    print('------------------------')\n",
    "    print('ATENCIÓN: '+atenticion)\n",
    "    print(df[df['ATENCIÓN']==atenticion]['TIPO RECUPERACIÓN'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good for every feature, becasue NO INFO means there is not values (nan). And RECUPERADO must be the only one with valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if ASINTOMATICO FIS have different values for Estado when  Estado='ASINTOMATICO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['LEVE', 'ASINTOMATICO', 'FALLECIDO', 'NO INFO', 'MODERADO',\n       'GRAVE'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "#si tipo de recuperacón presente solo esta para los de atención=RECUPERADO\n",
    "df[~(df['ASINTOMÁTICO FIS']=='ASINTOMATICO')]['ESTADO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASINTOMÁTICO FIS=ASINTOMATICO must not appear when looking in Estado!= ASINTOMATICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        ID DE CASO FECHA DE NOTIFICACIÓN  CÓDIGO DIVIPOLA  \\\n25              26            2020-03-15            13001   \n26              27            2020-03-15            13001   \n40              41            2020-03-14            41001   \n47              48            2020-03-15            11001   \n84              85            2020-03-17            76001   \n...            ...                   ...              ...   \n742122      742163            2020-09-15            11001   \n742123      742164            2020-09-16            11001   \n742309      742350            2020-09-13            54001   \n742334      742375            2020-09-14             8001   \n742337      742378            2020-09-15            76001   \n\n        CIUDAD DE UBICACIÓN DEPARTAMENTO O DISTRITO     ATENCIÓN  EDAD SEXO  \\\n25      CARTAGENA DE INDIAS      CARTAGENA D.T. Y C.  RECUPERADO    30    F   \n26      CARTAGENA DE INDIAS      CARTAGENA D.T. Y C.  RECUPERADO    30    F   \n40                    NEIVA                    HUILA  RECUPERADO    79    M   \n47              BOGOTA D.C.              BOGOTA D.C.  RECUPERADO    31    M   \n84                     CALI          VALLE DEL CAUCA  RECUPERADO    42    F   \n...                     ...                      ...         ...   ...  ...   \n742122          BOGOTA D.C.              BOGOTA D.C.        CASA    62    M   \n742123          BOGOTA D.C.              BOGOTA D.C.        CASA    29    M   \n742309               CUCUTA       NORTE DE SANTANDER        CASA     2    F   \n742334         BARRANQUILLA        BARRANQUILLA D.E.        CASA    50    F   \n742337                 CALI          VALLE DEL CAUCA        CASA    38    M   \n\n               TIPO        ESTADO PAÍS DE PROCEDENCIA FIS FECHA DE MUERTE  \\\n25      RELACIONADO  ASINTOMATICO             NO INFO NaT             NaT   \n26      RELACIONADO  ASINTOMATICO             NO INFO NaT             NaT   \n40      RELACIONADO  ASINTOMATICO             NO INFO NaT             NaT   \n47      RELACIONADO  ASINTOMATICO             NO INFO NaT             NaT   \n84      RELACIONADO  ASINTOMATICO             NO INFO NaT             NaT   \n...             ...           ...                 ...  ..             ...   \n742122   EN ESTUDIO  ASINTOMATICO             NO INFO NaT             NaT   \n742123   EN ESTUDIO  ASINTOMATICO             NO INFO NaT             NaT   \n742309   EN ESTUDIO  ASINTOMATICO             NO INFO NaT             NaT   \n742334   EN ESTUDIO  ASINTOMATICO             NO INFO NaT             NaT   \n742337   EN ESTUDIO  ASINTOMATICO             NO INFO NaT             NaT   \n\n       FECHA DIAGNOSTICO FECHA RECUPERADO FECHA REPORTE WEB TIPO RECUPERACIÓN  \\\n25            2020-03-15       2020-03-25        2020-03-15               PCR   \n26            2020-03-15       2020-03-25        2020-03-15               PCR   \n40            2020-03-14       2020-03-28        2020-03-14               PCR   \n47            2020-03-16       2020-03-27        2020-03-16               PCR   \n84            2020-03-17       2020-05-31        2020-03-17               PCR   \n...                  ...              ...               ...               ...   \n742122        2020-09-15              NaT        2020-09-17           NO INFO   \n742123        2020-09-16              NaT        2020-09-17           NO INFO   \n742309        2020-09-16              NaT        2020-09-17           NO INFO   \n742334        2020-09-15              NaT        2020-09-17           NO INFO   \n742337        2020-09-16              NaT        2020-09-17           NO INFO   \n\n        CODIGO DEPARTAMENTO  CODIGO PAIS PERTENENCIA ETNICA  \\\n25                       13          NaN               OTRO   \n26                       13          NaN               OTRO   \n40                       41          NaN               OTRO   \n47                       11          NaN               OTRO   \n84                       76          NaN               OTRO   \n...                     ...          ...                ...   \n742122                   11          NaN            NO INFO   \n742123                   11          NaN            NO INFO   \n742309                   54          NaN            NO INFO   \n742334                    8          NaN            NO INFO   \n742337                   76          NaN            NO INFO   \n\n       NOMBRE GRUPO ETNICO  ASINTOMÁTICO FIS  \n25                 NO INFO               NaN  \n26                 NO INFO               NaN  \n40                 NO INFO               NaN  \n47                 NO INFO               NaN  \n84                 NO INFO               NaN  \n...                    ...               ...  \n742122             NO INFO               NaN  \n742123             NO INFO               NaN  \n742309             NO INFO               NaN  \n742334             NO INFO               NaN  \n742337             NO INFO               NaN  \n\n[92416 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID DE CASO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>CÓDIGO DIVIPOLA</th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>EDAD</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>CODIGO DEPARTAMENTO</th>\n      <th>CODIGO PAIS</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n      <th>ASINTOMÁTICO FIS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>2020-03-15</td>\n      <td>13001</td>\n      <td>CARTAGENA DE INDIAS</td>\n      <td>CARTAGENA D.T. Y C.</td>\n      <td>RECUPERADO</td>\n      <td>30</td>\n      <td>F</td>\n      <td>RELACIONADO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-03-15</td>\n      <td>2020-03-25</td>\n      <td>2020-03-15</td>\n      <td>PCR</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>2020-03-15</td>\n      <td>13001</td>\n      <td>CARTAGENA DE INDIAS</td>\n      <td>CARTAGENA D.T. Y C.</td>\n      <td>RECUPERADO</td>\n      <td>30</td>\n      <td>F</td>\n      <td>RELACIONADO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-03-15</td>\n      <td>2020-03-25</td>\n      <td>2020-03-15</td>\n      <td>PCR</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>2020-03-14</td>\n      <td>41001</td>\n      <td>NEIVA</td>\n      <td>HUILA</td>\n      <td>RECUPERADO</td>\n      <td>79</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-03-14</td>\n      <td>2020-03-28</td>\n      <td>2020-03-14</td>\n      <td>PCR</td>\n      <td>41</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>48</td>\n      <td>2020-03-15</td>\n      <td>11001</td>\n      <td>BOGOTA D.C.</td>\n      <td>BOGOTA D.C.</td>\n      <td>RECUPERADO</td>\n      <td>31</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-03-16</td>\n      <td>2020-03-27</td>\n      <td>2020-03-16</td>\n      <td>PCR</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>85</td>\n      <td>2020-03-17</td>\n      <td>76001</td>\n      <td>CALI</td>\n      <td>VALLE DEL CAUCA</td>\n      <td>RECUPERADO</td>\n      <td>42</td>\n      <td>F</td>\n      <td>RELACIONADO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-03-17</td>\n      <td>2020-05-31</td>\n      <td>2020-03-17</td>\n      <td>PCR</td>\n      <td>76</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>742122</th>\n      <td>742163</td>\n      <td>2020-09-15</td>\n      <td>11001</td>\n      <td>BOGOTA D.C.</td>\n      <td>BOGOTA D.C.</td>\n      <td>CASA</td>\n      <td>62</td>\n      <td>M</td>\n      <td>EN ESTUDIO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-09-15</td>\n      <td>NaT</td>\n      <td>2020-09-17</td>\n      <td>NO INFO</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NO INFO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>742123</th>\n      <td>742164</td>\n      <td>2020-09-16</td>\n      <td>11001</td>\n      <td>BOGOTA D.C.</td>\n      <td>BOGOTA D.C.</td>\n      <td>CASA</td>\n      <td>29</td>\n      <td>M</td>\n      <td>EN ESTUDIO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-09-16</td>\n      <td>NaT</td>\n      <td>2020-09-17</td>\n      <td>NO INFO</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NO INFO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>742309</th>\n      <td>742350</td>\n      <td>2020-09-13</td>\n      <td>54001</td>\n      <td>CUCUTA</td>\n      <td>NORTE DE SANTANDER</td>\n      <td>CASA</td>\n      <td>2</td>\n      <td>F</td>\n      <td>EN ESTUDIO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-09-16</td>\n      <td>NaT</td>\n      <td>2020-09-17</td>\n      <td>NO INFO</td>\n      <td>54</td>\n      <td>NaN</td>\n      <td>NO INFO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>742334</th>\n      <td>742375</td>\n      <td>2020-09-14</td>\n      <td>8001</td>\n      <td>BARRANQUILLA</td>\n      <td>BARRANQUILLA D.E.</td>\n      <td>CASA</td>\n      <td>50</td>\n      <td>F</td>\n      <td>EN ESTUDIO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-09-15</td>\n      <td>NaT</td>\n      <td>2020-09-17</td>\n      <td>NO INFO</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NO INFO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>742337</th>\n      <td>742378</td>\n      <td>2020-09-15</td>\n      <td>76001</td>\n      <td>CALI</td>\n      <td>VALLE DEL CAUCA</td>\n      <td>CASA</td>\n      <td>38</td>\n      <td>M</td>\n      <td>EN ESTUDIO</td>\n      <td>ASINTOMATICO</td>\n      <td>NO INFO</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>2020-09-16</td>\n      <td>NaT</td>\n      <td>2020-09-17</td>\n      <td>NO INFO</td>\n      <td>76</td>\n      <td>NaN</td>\n      <td>NO INFO</td>\n      <td>NO INFO</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>92416 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "t=df[~(df['ASINTOMÁTICO FIS']=='ASINTOMATICO')]\n",
    "t[t.ESTADO=='ASINTOMATICO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([nan])"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "df[(df['ESTADO']=='ASINTOMATICO')]['ASINTOMÁTICO FIS'].unique()"
   ]
  },
  {
   "source": [
    "Seem that FIS has been fixed, as in previous versions of the database,FIS contains string values as 'Asintomático'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping 'ASINTOMÁTICO FIS'\n",
    "df.drop(columns=['ASINTOMÁTICO FIS'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the 'Tipo' values for each unique value of 'atención'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------------------\nRECUPERADO\nEN ESTUDIO     577183\nRELACIONADO     37328\nIMPORTADO         946\nName: TIPO, dtype: int64\n-------------------------\nFALLECIDO\nEN ESTUDIO     23006\nRELACIONADO      636\nIMPORTADO         23\nName: TIPO, dtype: int64\n-------------------------\nNO INFO\nEN ESTUDIO     1513\nRELACIONADO      43\nName: TIPO, dtype: int64\n-------------------------\nCASA\nEN ESTUDIO     87819\nRELACIONADO      800\nIMPORTADO          4\nName: TIPO, dtype: int64\n-------------------------\nHOSPITAL\nEN ESTUDIO     13110\nRELACIONADO      104\nIMPORTADO          4\nName: TIPO, dtype: int64\n-------------------------\nHOSPITAL UCI\nEN ESTUDIO     1026\nRELACIONADO       8\nName: TIPO, dtype: int64\n"
    }
   ],
   "source": [
    "for values in df['ATENCIÓN'].unique():\n",
    "    print('-------------------------')\n",
    "    print(values)\n",
    "    print(df[df['ATENCIÓN']==values]['TIPO'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating that we have not different values for atentción feature when Estado = 'FALLECIDO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [ID DE CASO, FECHA DE NOTIFICACIÓN, CÓDIGO DIVIPOLA, CIUDAD DE UBICACIÓN, DEPARTAMENTO O DISTRITO , ATENCIÓN, EDAD, SEXO, TIPO, ESTADO, PAÍS DE PROCEDENCIA, FIS, FECHA DE MUERTE, FECHA DIAGNOSTICO, FECHA RECUPERADO, FECHA REPORTE WEB, TIPO RECUPERACIÓN, CODIGO DEPARTAMENTO, CODIGO PAIS, PERTENENCIA ETNICA, NOMBRE GRUPO ETNICO]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID DE CASO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>CÓDIGO DIVIPOLA</th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>EDAD</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>CODIGO DEPARTAMENTO</th>\n      <th>CODIGO PAIS</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "df[(df['ESTADO']=='FALLECIDO') & (df['ATENCIÓN']!='FALLECIDO')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem's good.\n",
    "\n",
    "Next thing to do is check that we have no dates like Fecha de muerte prior fecha de notificación or diagnostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "FECHA DE NOTIFICACIÓN    False\nFIS                       True\nFECHA DE MUERTE           True\nFECHA DIAGNOSTICO         True\nFECHA RECUPERADO          True\nFECHA REPORTE WEB        False\ndtype: bool"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df.select_dtypes(include='datetime').isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 743553 entries, 0 to 743944\nData columns (total 6 columns):\n #   Column                 Non-Null Count   Dtype         \n---  ------                 --------------   -----         \n 0   FECHA DE NOTIFICACIÓN  743553 non-null  datetime64[ns]\n 1   FIS                    651137 non-null  datetime64[ns]\n 2   FECHA DE MUERTE        25290 non-null   datetime64[ns]\n 3   FECHA DIAGNOSTICO      739484 non-null  datetime64[ns]\n 4   FECHA RECUPERADO       615457 non-null  datetime64[ns]\n 5   FECHA REPORTE WEB      743553 non-null  datetime64[ns]\ndtypes: datetime64[ns](6)\nmemory usage: 39.7 MB\n"
    }
   ],
   "source": [
    "df.select_dtypes(include='datetime').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have various dates with null values, need to take in mind those when cheking for prior dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the df, using only the index that met the Fecha de notificación <= Fecha reporte web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False    743069\nTrue        484\ndtype: int64\n(743069, 21)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID DE CASO FECHA DE NOTIFICACIÓN  CÓDIGO DIVIPOLA  CIUDAD DE UBICACIÓN  \\\n0           1            2020-03-02            11001          BOGOTA D.C.   \n1           2            2020-03-06            76111  GUADALAJARA DE BUGA   \n2           3            2020-03-07             5001             MEDELLIN   \n3           4            2020-03-09             5001             MEDELLIN   \n4           5            2020-03-09             5001             MEDELLIN   \n\n  DEPARTAMENTO O DISTRITO     ATENCIÓN  EDAD SEXO         TIPO ESTADO  \\\n0              BOGOTA D.C.  RECUPERADO    19    F    IMPORTADO   LEVE   \n1          VALLE DEL CAUCA  RECUPERADO    34    M    IMPORTADO   LEVE   \n2                ANTIOQUIA  RECUPERADO    50    F    IMPORTADO   LEVE   \n3                ANTIOQUIA  RECUPERADO    55    M  RELACIONADO   LEVE   \n4                ANTIOQUIA  RECUPERADO    25    M  RELACIONADO   LEVE   \n\n  PAÍS DE PROCEDENCIA        FIS FECHA DE MUERTE FECHA DIAGNOSTICO  \\\n0              ITALIA 2020-02-27             NaT        2020-03-06   \n1              ESPANA 2020-03-04             NaT        2020-03-09   \n2              ESPANA 2020-02-29             NaT        2020-03-09   \n3             NO INFO 2020-03-06             NaT        2020-03-11   \n4             NO INFO 2020-03-08             NaT        2020-03-11   \n\n  FECHA RECUPERADO FECHA REPORTE WEB TIPO RECUPERACIÓN  CODIGO DEPARTAMENTO  \\\n0       2020-03-13        2020-03-06               PCR                   11   \n1       2020-03-19        2020-03-09               PCR                   76   \n2       2020-03-15        2020-03-09               PCR                    5   \n3       2020-03-26        2020-03-11               PCR                    5   \n4       2020-03-23        2020-03-11               PCR                    5   \n\n   CODIGO PAIS PERTENENCIA ETNICA NOMBRE GRUPO ETNICO  \n0        380.0               OTRO             NO INFO  \n1        724.0              NEGRO             NO INFO  \n2        724.0               OTRO             NO INFO  \n3          NaN               OTRO             NO INFO  \n4          NaN               OTRO             NO INFO  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID DE CASO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>CÓDIGO DIVIPOLA</th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>EDAD</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>CODIGO DEPARTAMENTO</th>\n      <th>CODIGO PAIS</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-03-02</td>\n      <td>11001</td>\n      <td>BOGOTA D.C.</td>\n      <td>BOGOTA D.C.</td>\n      <td>RECUPERADO</td>\n      <td>19</td>\n      <td>F</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ITALIA</td>\n      <td>2020-02-27</td>\n      <td>NaT</td>\n      <td>2020-03-06</td>\n      <td>2020-03-13</td>\n      <td>2020-03-06</td>\n      <td>PCR</td>\n      <td>11</td>\n      <td>380.0</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020-03-06</td>\n      <td>76111</td>\n      <td>GUADALAJARA DE BUGA</td>\n      <td>VALLE DEL CAUCA</td>\n      <td>RECUPERADO</td>\n      <td>34</td>\n      <td>M</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ESPANA</td>\n      <td>2020-03-04</td>\n      <td>NaT</td>\n      <td>2020-03-09</td>\n      <td>2020-03-19</td>\n      <td>2020-03-09</td>\n      <td>PCR</td>\n      <td>76</td>\n      <td>724.0</td>\n      <td>NEGRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2020-03-07</td>\n      <td>5001</td>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>50</td>\n      <td>F</td>\n      <td>IMPORTADO</td>\n      <td>LEVE</td>\n      <td>ESPANA</td>\n      <td>2020-02-29</td>\n      <td>NaT</td>\n      <td>2020-03-09</td>\n      <td>2020-03-15</td>\n      <td>2020-03-09</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>724.0</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2020-03-09</td>\n      <td>5001</td>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>55</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>LEVE</td>\n      <td>NO INFO</td>\n      <td>2020-03-06</td>\n      <td>NaT</td>\n      <td>2020-03-11</td>\n      <td>2020-03-26</td>\n      <td>2020-03-11</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2020-03-09</td>\n      <td>5001</td>\n      <td>MEDELLIN</td>\n      <td>ANTIOQUIA</td>\n      <td>RECUPERADO</td>\n      <td>25</td>\n      <td>M</td>\n      <td>RELACIONADO</td>\n      <td>LEVE</td>\n      <td>NO INFO</td>\n      <td>2020-03-08</td>\n      <td>NaT</td>\n      <td>2020-03-11</td>\n      <td>2020-03-23</td>\n      <td>2020-03-11</td>\n      <td>PCR</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>OTRO</td>\n      <td>NO INFO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "s=(df['FECHA REPORTE WEB']-df['FECHA DE NOTIFICACIÓN'])\n",
    "print((s<dt.timedelta(0)).value_counts())\n",
    "#Updating the df with the values that met the condition\n",
    "df=df.loc[s[(s>=dt.timedelta(0))].index]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 205 values where Fecha reporte web  is prior to fecha de notificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the following condution must be met:\n",
    "\n",
    "* 'FIS'<'Fecha diagnostico'<'Fecha recuperado'\n",
    "\n",
    "* 'FIS'<'Fecha diagnostico'<'Fecha de muerte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Bad approach as we comparing items with missing values\n",
    "# s2=(df['FIS']<df['Fecha diagnostico'])\n",
    "# print(s2.value_counts())\n",
    "# s2[~s2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 743069/743069 [05:46<00:00, 2144.43it/s]\n"
    }
   ],
   "source": [
    "# Because we dont have every value, we just focus in those who are NaT. Compare only if both series have a value. otherwise skip\n",
    "idx_met=[]\n",
    "idx_nmet=[]\n",
    "idx_null=[]\n",
    "for x in tqdm(df.index):\n",
    "    if pd.notna(df['FIS'][x]) and pd.notna(df['FECHA DIAGNOSTICO'][x]):\n",
    "        if df['FIS'][x]<df['FECHA DIAGNOSTICO'][x]:\n",
    "            idx_met.append(x)\n",
    "        else:\n",
    "            idx_nmet.append(x)\n",
    "    else:\n",
    "        idx_null.append(x)"
   ]
  },
  {
   "source": [
    "### Checking why we ahve NaT values in FECHA DIAGNOSTICO "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       FECHA DIAGNOSTICO FECHA DE NOTIFICACIÓN        FIS\n4778          2020-03-23            2020-03-24 2020-03-15\n6604          2020-04-30            2020-05-01        NaT\n6605          2020-04-30            2020-05-01        NaT\n6606          2020-04-30            2020-05-01        NaT\n6607          2020-04-30            2020-05-01        NaT\n...                  ...                   ...        ...\n731107        2020-09-03            2020-09-15 2020-08-20\n731145        2020-08-28            2020-09-15 2020-08-16\n731184        2020-08-25            2020-09-10 2020-08-11\n731226        2020-08-09            2020-08-27 2020-08-03\n731327        2020-08-16            2020-09-15 2020-08-02\n\n[19109 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>FIS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4778</th>\n      <td>2020-03-23</td>\n      <td>2020-03-24</td>\n      <td>2020-03-15</td>\n    </tr>\n    <tr>\n      <th>6604</th>\n      <td>2020-04-30</td>\n      <td>2020-05-01</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>6605</th>\n      <td>2020-04-30</td>\n      <td>2020-05-01</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>6606</th>\n      <td>2020-04-30</td>\n      <td>2020-05-01</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>6607</th>\n      <td>2020-04-30</td>\n      <td>2020-05-01</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>731107</th>\n      <td>2020-09-03</td>\n      <td>2020-09-15</td>\n      <td>2020-08-20</td>\n    </tr>\n    <tr>\n      <th>731145</th>\n      <td>2020-08-28</td>\n      <td>2020-09-15</td>\n      <td>2020-08-16</td>\n    </tr>\n    <tr>\n      <th>731184</th>\n      <td>2020-08-25</td>\n      <td>2020-09-10</td>\n      <td>2020-08-11</td>\n    </tr>\n    <tr>\n      <th>731226</th>\n      <td>2020-08-09</td>\n      <td>2020-08-27</td>\n      <td>2020-08-03</td>\n    </tr>\n    <tr>\n      <th>731327</th>\n      <td>2020-08-16</td>\n      <td>2020-09-15</td>\n      <td>2020-08-02</td>\n    </tr>\n  </tbody>\n</table>\n<p>19109 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "df[df['FECHA DIAGNOSTICO']<df['FECHA DE NOTIFICACIÓN']][['FECHA DIAGNOSTICO','FECHA DE NOTIFICACIÓN','FIS']]"
   ]
  },
  {
   "source": [
    "the majority of Dates of FECHA DIAGNOSTICO are post FECHA DE NOTIFICACIÓN, so what is the diference between those ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [ID DE CASO, FECHA DE NOTIFICACIÓN, CÓDIGO DIVIPOLA, CIUDAD DE UBICACIÓN, DEPARTAMENTO O DISTRITO , ATENCIÓN, EDAD, SEXO, TIPO, ESTADO, PAÍS DE PROCEDENCIA, FIS, FECHA DE MUERTE, FECHA DIAGNOSTICO, FECHA RECUPERADO, FECHA REPORTE WEB, TIPO RECUPERACIÓN, CODIGO DEPARTAMENTO, CODIGO PAIS, PERTENENCIA ETNICA, NOMBRE GRUPO ETNICO]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID DE CASO</th>\n      <th>FECHA DE NOTIFICACIÓN</th>\n      <th>CÓDIGO DIVIPOLA</th>\n      <th>CIUDAD DE UBICACIÓN</th>\n      <th>DEPARTAMENTO O DISTRITO</th>\n      <th>ATENCIÓN</th>\n      <th>EDAD</th>\n      <th>SEXO</th>\n      <th>TIPO</th>\n      <th>ESTADO</th>\n      <th>PAÍS DE PROCEDENCIA</th>\n      <th>FIS</th>\n      <th>FECHA DE MUERTE</th>\n      <th>FECHA DIAGNOSTICO</th>\n      <th>FECHA RECUPERADO</th>\n      <th>FECHA REPORTE WEB</th>\n      <th>TIPO RECUPERACIÓN</th>\n      <th>CODIGO DEPARTAMENTO</th>\n      <th>CODIGO PAIS</th>\n      <th>PERTENENCIA ETNICA</th>\n      <th>NOMBRE GRUPO ETNICO</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "df[df['FECHA DE NOTIFICACIÓN']<df['FIS']]"
   ]
  },
  {
   "source": [
    "It is a good sign that  we do not have dates FECHA DE NOTIFICACIÓN post FIS.\n",
    "\n",
    "But what happens insigts privide NaT values of FECHA DIAGNOSTICO?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LEVE            3537\nFALLECIDO        204\nASINTOMATICO      38\nMODERADO          36\nNO INFO           27\nGRAVE             10\nName: ESTADO, dtype: int64"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "df[df['FECHA DIAGNOSTICO'].isna()]['ESTADO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Percentage 0.521% of missing FECHA DIAGNOSTICO dates in regard with the whole data  743069\n"
    }
   ],
   "source": [
    "print('Percentage {:2.3f}% of missing FECHA DIAGNOSTICO dates in regard with the whole data '.format(100*len(df[df['FECHA DIAGNOSTICO'].isna()])/len(df[pd.notnull(df['FECHA DIAGNOSTICO'])])),len(df))"
   ]
  },
  {
   "source": [
    "Two things that we can see is that the percentage of missing dates are not meaningful and we have different values for ESTADO.\n",
    "\n",
    "In order with that, I considered two actions to take:\n",
    "\n",
    "1. Drop every NaT value for FECHA DIAGNOSTICO\n",
    "2. Work with FECHA NOTIFICACÓN  instead of FECHA DIAGNOSTICO.\n",
    "\n",
    "I choose to the the first action (1.) because it make sense that only people that have been seem by a doctor or related are the ones with/without the virus and the amount of data with out the date is low compared with the whole data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 33.8 MiB for an array with shape (6, 739217) and data type datetime64[ns]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-2df51850e172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Droping NaT row from FECHA DIAGNOSTICO in df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FECHA DIAGNOSTICO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4160\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4161\u001b[0m         \"\"\"\n\u001b[1;32m-> 4162\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4163\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4164\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3882\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3884\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3918\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3919\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3921\u001b[0m         \u001b[1;31m# Case for non-unique axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4029\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4030\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4031\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4033\u001b[0m     def drop(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4457\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4458\u001b[1;33m         return self._reindex_axes(\n\u001b[0m\u001b[0;32m   4459\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4460\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   3875\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3876\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3877\u001b[1;33m             frame = frame._reindex_index(\n\u001b[0m\u001b[0;32m   3878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3879\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   3894\u001b[0m             \u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3895\u001b[0m         )\n\u001b[1;32m-> 3896\u001b[1;33m         return self._reindex_with_indexers(\n\u001b[0m\u001b[0;32m   3897\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3898\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4520\u001b[0m             \u001b[1;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4521\u001b[1;33m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[0;32m   4522\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4523\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[0;32m   1282\u001b[0m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             new_blocks = [\n\u001b[0m\u001b[0;32m   1285\u001b[0m                 blk.take_nd(\n\u001b[0;32m   1286\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m             new_blocks = [\n\u001b[1;32m-> 1285\u001b[1;33m                 blk.take_nd(\n\u001b[0m\u001b[0;32m   1286\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         new_values = algos.take_nd(\n\u001b[0m\u001b[0;32m   1255\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1701\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 33.8 MiB for an array with shape (6, 739217) and data type datetime64[ns]"
     ]
    }
   ],
   "source": [
    "#Droping NaT row from FECHA DIAGNOSTICO in df\n",
    "df.drop(df[df['FECHA DIAGNOSTICO'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ASINTOMATICO    92396\nName: ESTADO, dtype: int64"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "df[df['FIS'].isna()]['ESTADO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LEVE         600653\nFALLECIDO     23640\nMODERADO      22416\nGRAVE          2194\nNO INFO        1770\nName: ESTADO, dtype: int64"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "df[pd.notnull(df['FIS'])]['ESTADO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(idx_met[-10:])\n",
    "print('Len of index that met the condition: {}'.format(len(idx_met)))\n",
    "print('Len of index that NOT met the condition: {}'.format(len(idx_nmet)))\n",
    "print('Len of Null index : {}'.format(len(idx_null)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1050 that not met the condition 'FIS'<'Fecha diagnostico', So we need to drop those index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Droping index that not met\n",
    "df.drop(idx_nmet,inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check:\n",
    "\n",
    "* 'Fecha diagnostico'<'Fecha recuperado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_met=[]\n",
    "idx_nmet=[]\n",
    "idx_null=[]\n",
    "for x in tqdm(df.index):\n",
    "    if pd.notna(df['FECHA DIAGNOSTICO'][x]) and pd.notna(df['FECHA RECUPERADO'][x]):\n",
    "        if df['FECHA DIAGNOSTICO'][x]<df['FECHA RECUPERADO'][x]:\n",
    "            idx_met.append(x)\n",
    "        else:\n",
    "            idx_nmet.append(x)\n",
    "    else:\n",
    "        idx_null.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Len of index that met the condition: {}'.format(len(idx_met)))\n",
    "print('Len of index that NOT met the condition: {}'.format(len(idx_nmet)))\n",
    "print('Len of Null index : {}'.format(len(idx_null)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Droping index that not met\n",
    "df.drop(idx_nmet,inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the people who were diagnosed with COVID after death:\n",
    "\n",
    "* 'Fecha diagnostico'<'Fecha de muerte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_met=[]\n",
    "idx_nmet=[]\n",
    "idx_null=[]\n",
    "for x in tqdm(df.index):\n",
    "    if pd.notna(df['Fecha diagnostico'][x]) and pd.notna(df['Fecha de muerte'][x]):\n",
    "        if df['Fecha diagnostico'][x]<df['Fecha de muerte'][x]:\n",
    "            idx_met.append(x)\n",
    "        else:\n",
    "            idx_nmet.append(x)\n",
    "    else:\n",
    "        idx_null.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('{} People diagnosed with COVID after death'.format(len(idx_nmet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not drop those index as that is a insight of the People who were diagnosed with COVID after death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that we have no values for both 'Fecha recuperado' and 'Fecha de muerte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filtering only not null values for Fecha recueprado in the df\n",
    "print('Null values in DF for Fecha recuperado : \\t')\n",
    "print(df[pd.notnull(df['Fecha recuperado'])]['Fecha recuperado'].isnull().unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asking if there is a null value in each row, True is yes and False if there is a date\n",
    "df[pd.notnull(df['Fecha recuperado'])]['Fecha de muerte'].isnull().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dates in the same row for 'Fecha de mmuerte' and 'Fecha recueprado'.\n",
    "\n",
    "We must drop those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NO SE PEUDE HACER PORQUE NO ESOTY TENIENDO EN CUENTA OTROS VALARES NULOS, ESTARIA PERDIENDO INFORMACIÓN\n",
    "# #checking the values that have no Fecha de muerte\n",
    "# temp=df[pd.notnull(df['Fecha recuperado'])]\n",
    "# idx_frfd=temp[temp['Fecha de muerte'].isnull()].index\n",
    "# print(temp[temp['Fecha de muerte'].isnull()]['Fecha de muerte'].unique())\n",
    "# idx_frfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_met=[]\n",
    "for x in df.index:\n",
    "    if pd.notna(df['Fecha recuperado'][x]) and pd.notna(df['Fecha de muerte'][x]):\n",
    "        idx_met.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Len of index that met the condition: {}'.format(len(idx_met)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop those values, because qe can not have a date for a recoverd people but also shows a date of death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#droping the values that present in both Fecha recuperado and Fecha de muerte \n",
    "df.drop(idx_met,inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheking numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=np.number).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have missing values in Codigo pais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cheking if we have no duplicates in ID de caso\n",
    "df['ID de caso'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Código DIVIPOLA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cheking unique values in Edad\n",
    "print(sorted(df['Edad'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting look the people over 100 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cheking unique values in Codigo departamento\n",
    "print(sorted(df['Codigo departamento'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cheking unique values in Codigo pais\n",
    "print(sorted(df['Codigo pais'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the ages over 99 years old\n",
    "df[df['Edad']>99]#.select_dtypes(exclude='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 62 people over 99 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Edad']>99].to_excel('personas_mayores_99.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droping those people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Edad']>99].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that for Estado=ASINTOMATICO have no Fecha de muerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[df['Estado']=='ASINTOMATICO']\n",
    "temp2=temp[temp['Fecha de muerte'].notnull()]\n",
    "temp2['M<D']=df['Fecha diagnostico']>df['Fecha de muerte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have asymptomatic people with a date of death, we must review their date of diagnosis, because possibly these people died and after they died they were diagnosed with COVID, however they did not die from COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == True\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp2[['Estado','Fecha recuperado','Fecha diagnostico','Fecha de muerte','M<D']].style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the highlighted values shows the people that died before diagnosed with COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('We have {} \"ASINTOMATICO\" people that have dates of Fecha de dianostico and fecha de muerte'.format(len(temp2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last check,we must not have values for Tipo de recuperacion when there is a date Fecha de muerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[pd.notnull(df['Fecha de muerte'])]['Tipo recuperación'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Division politica administrativa DIVIPOLA\n",
    "* FECHA Inicio sintomas FIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('pre_cleaned_dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vamos a ver los casos activos por cada municipio, para ello iimportamos la polacion que el DANE proporciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_excel('Datos municipios 2020.xlsx')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping duplicate columns\n",
    "df2.drop(columns=['Departamento','Nombre_Departamento','Misión_Rural'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de Municipio a cod DIVIPOLA y 2020 a Población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'Municipio':'Código DIVIPOLA',2020:'Población'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hicimos un merge tipo left de los dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedf=pd.merge(df,df2,how='left',on='Código DIVIPOLA')\n",
    "mergedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedf.atención.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking the atention values different than Fallecido, Recuperado and nan, the resulting df (temp_m1) contains only active cases\n",
    "temp_m1=mergedf[~mergedf['atención'].isin(['Fallecido','Recuperado','NO INFO'])]#np.nan])]\n",
    "temp_m1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grouping active COVID cases\n",
    "casos_activos=temp_m1.groupby('Código DIVIPOLA')['ID de caso'].count().reset_index(name='total_casos_activos')\n",
    "print(type(casos_activos))\n",
    "casos_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged casos_activos with df2\n",
    "casos_activos_poblacion=casos_activos.merge(df2,how='left', on='Código DIVIPOLA').rename(columns={2020:'poblacion'})\n",
    "casos_activos_poblacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_activos_poblacion[casos_activos_poblacion['Nombre_Municipio']=='Chía']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casos activos millon de habitantes\n",
    "casos_activos_poblacion['casosxmillon']=1000000*casos_activos_poblacion['total_casos_activos']/casos_activos_poblacion['Población'] \n",
    "\n",
    "#sorting by casos por millon (casosxmillon)\n",
    "casos_activos_poblacion.sort_values(by=['casosxmillon'],ascending=False,inplace=True)\n",
    "\n",
    "casos_activos_poblacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_activos_poblacion.to_excel('tabla.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#casos_activos_poblacion['casosxmillon'].sort_values(ascending=False).head(10).plot(kind='bar')\n",
    "casos_activos_poblacion.sort_values(by='casosxmillon',ascending=False).head(10).plot(x='Nombre_Municipio',y='casosxmillon',kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_activos_poblacion.groupby('Clima')['casosxmillon'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo locations of Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo=pd.read_csv('geo_municipios.csv')\n",
    "geo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding values to latitud \n",
    "geo.latitud=geo.nombre_tipo_ctro_pbdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the index because we have dupplicated index\n",
    "geo.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[geo['codigo_departamento']==99773]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we have different names for nombre_departamento and nombre_municipio, we're only interested on those who match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #looking for the index that match on 'nombre_departamento' and'nombre_municipio'\n",
    "# geo_idx=[]\n",
    "# for nombre in geo.index:\n",
    "#     if geo['nombre_departamento'][nombre]==geo['nombre_municipio'][nombre]:\n",
    "#         geo_idx.append(nombre)\n",
    "\n",
    "print(geo[geo['nombre_centro_poblado']=='CABECERA MUNICIPAL'].isnull().any())\n",
    "geo[geo['nombre_centro_poblado']=='CABECERA MUNICIPAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[geo['nombre_centro_poblado']=='CABECERA MUNICIPAL']['codigo_departamento'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating geo DataFrame\n",
    "geo_idx=geo[geo['nombre_centro_poblado']=='CABECERA MUNICIPAL'].index\n",
    "geo=geo.loc[geo_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming codigo_departamento to Código DIVIPOLA, for future merge with casos_activos_poblacion DataFrame\n",
    "geo.rename(columns={'codigo_departamento':'Código DIVIPOLA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are keeping codigo_departamento(Código DIVIPOLA) nombre_departamento longitud and latitud\n",
    "geo=geo[['Código DIVIPOLA','nombre_departamento', 'longitud', 'latitud']]\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[geo['Código DIVIPOLA']==11001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging geo with casos_activos_poblacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos=casos_activos_poblacion.merge(geo,how='left',on='Código DIVIPOLA')\n",
    "geo_casos_activos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=geo_casos_activos[(geo_casos_activos['longitud'].isnull())|(geo_casos_activos['latitud'].isnull())]\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('We have {} values without longitud or latitud'.format(len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Nombre_Municipio'].unique()\n",
    "#Create a DataFrame that contains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_casos_activos['nombre_departamento']=geo_casos_activos['Nombre_Municipio'].progress_apply(lambda x: x.upper()+' COLOMBIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing adding latitude and logitude if there is a nan in those columns\n",
    "\n",
    "#uncomment for check example\n",
    "# print(geolocator.geocode(\"Barranquilla Colombia\")[1])\n",
    "# (geolocator.geocode(\"Barranquilla Colombia\").latitude,geolocator.geocode(\"Bogotá Colombia\").longitude)\n",
    "\n",
    "# uncomment for look in the DataFrame\n",
    "# geo_casos_activos.progress_apply(lambda x: (geolocator.geocode(x.nombre_departamento))[1] if (pd.isna(x.longitud))|(pd.isna(x.latitud)) else (x.longitud,x.latitud),axis=1)\n",
    "\n",
    "geo_casos_activos['latitud2']=geo_casos_activos.progress_apply(lambda x: (geolocator.geocode(x.nombre_departamento)).latitude if (pd.isna(x.longitud)) else x.longitud, axis=1)\n",
    "geo_casos_activos['longitud2']=geo_casos_activos.progress_apply(lambda x: (geolocator.geocode(x.nombre_departamento)).longitude if (pd.isna(x.latitud)) else x.latitud, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_casos_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos['Nombre_Municipio'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aternate aproaches to look for the longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#geo_casos_activos['latitud2']=geo_casos_activos['nombre_departamento'].progress_apply(lambda x: geolocator.geocode(x).latitude if geolocator.geocode(x) != None else 'NF')\n",
    "#geo_casos_activos['longitud2']=geo_casos_activos['nombre_departamento'].progress_apply(lambda x: geolocator.geocode(x).longitude if geolocator.geocode(x) != None else 'NF')\n",
    "\n",
    "#geo_casos_activos[geo_casos_activos['latitud2']=='NF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.where((geo_casos_activos.longitud.isna())|(geo_casos_activos.latitud.isna()),geo_casos_activos.Nombre_Municipio,(geo_casos_activos.longitud,geo_casos_activos.latitud))\n",
    "# pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos.plot(kind=\"scatter\", x=\"latitud2\", y=\"longitud2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is the attribute we'll map onto colors, s is the attribute we'll represent with circle size.\n",
    "geo_casos_activos.plot(kind=\"scatter\", x=\"latitud2\", y=\"longitud2\",\n",
    "    s=geo_casos_activos['casosxmillon']/100, label=\"CasosxMillon\",\n",
    "    c='Población', cmap=plt.get_cmap(\"jet\"),\n",
    "    colorbar=True, alpha=0.4, figsize=(10,7),\n",
    ")\n",
    "plt.legend()\n",
    "#save_fig(\"housing_prices_scatterplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[4.00,-72.00], default_zoom_start=6.4):\n",
    "    base_map = folium.Map(location=default_location,tiles='cartodbdark_matter', control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map=generateBaseMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "\n",
    "#HeatMap(data=df[['longitud', 'latitud', 'casosxmillon']].groupby(['longitud', 'latitud']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
    "\n",
    "HeatMap(data=geo_casos_activos[['latitud2','longitud2', 'casosxmillon']].values.tolist(),radius=8, max_zoom=13).add_to(base_map)\n",
    "\n",
    "# for i in range(0,len(geo_casos_activos)):\n",
    "#     HeatMap(\n",
    "#         data=[geo_casos_activos.iloc[i]['longitud2'], geo_casos_activos.iloc[i]['latitud2']],\n",
    "#         popup=geo_casos_activos.iloc[i]['Nombre_Municipio'],\n",
    "#         radius=geo_casos_activos.iloc[i]['casosxmillon']).add_to(base_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colombia = folium.Map(location=[4.00,-72.00],zoom_start=6.4)\n",
    "\n",
    "for i in range(0,len(geo_casos_activos)):\n",
    "    folium.Circle(\n",
    "        location=[geo_casos_activos.iloc[i]['latitud2'], geo_casos_activos.iloc[i]['longitud2']],\n",
    "        popup=(unidecode.unidecode(geo_casos_activos.iloc[i]['Nombre_Municipio']),\n",
    "               int(geo_casos_activos.iloc[i]['casosxmillon']),\n",
    "               unidecode.unidecode('Clima: '+geo_casos_activos.iloc[i]['Clima']),\n",
    "               'Altitud: '+ str(geo_casos_activos.iloc[i]['Altitud'])+'m'),\n",
    "        radius=geo_casos_activos.iloc[i]['casosxmillon'],\n",
    "        color='crimson',\n",
    "        fill=True,\n",
    "        fill_color='crimson').add_to(colombia)\n",
    "\n",
    "colombia.save(outfile='casos_activos.html')\n",
    "colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_casos_activos.iloc[[6,121,183,265,401,619,789]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example adding radius to heatmap using folium\n",
    "\n",
    "# import random\n",
    "# from folium import plugins\n",
    "\n",
    "# data = [[41.895278,12.482222,2873494.0,20.243001,20414,7.104243],\n",
    "#         [41.883850,12.333330,3916.0,0.835251,4,1.021450],\n",
    "#         [41.854241,12.567000,22263.0,1.132390,35,1.572115],\n",
    "#         [41.902147,12.590388,19505.0,0.839181,37,1.896950],\n",
    "#         [41.994240,12.48520,16239.0,1.383981,25,1.539504]]\n",
    "\n",
    "# dfdfdf = pd.DataFrame(columns=['latitude','longitude','population','radius','count','normalized'],data=data)\n",
    "\n",
    "# middle_lat = dfdfdf['latitude'].median()\n",
    "# middle_lon = dfdfdf['longitude'].median()\n",
    "# m = folium.Map(location=[middle_lat, middle_lon],tiles = \"Stamen Terrain\",zoom_start=11)\n",
    "\n",
    "# # convert to (n, 2) nd-array format for heatmap\n",
    "# points = dfdfdf[['latitude', 'longitude', 'normalized']].dropna().values\n",
    "\n",
    "# # plot heatmap\n",
    "# #plugins.HeatMap(points, radius=15).add_to(m)\n",
    "\n",
    "# pointArrays = np.split(points, len(points))\n",
    "# radii = [5, 10, 15, 20, 25]\n",
    "\n",
    "# for point, radius in zip(pointArrays, radii):\n",
    "#     plugins.HeatMap(point, radius=radius).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp = folium.Map(location=[middle_lat, middle_lon],tiles = \"Stamen Terrain\",zoom_start=11)\n",
    "mp = folium.Map(location=[4.00,-72.00],zoom_start=6.4,tiles='cartodbdark_matter')\n",
    "\n",
    "points = geo_casos_activos[['longitud','latitud','casosxmillon']].dropna().values\n",
    "\n",
    "pointArrays = np.split(points, len(points))\n",
    "radio=(geo_casos_activos['casosxmillon']/1000).tolist()\n",
    "\n",
    "for point, radius in zip(pointArrays, radio):\n",
    "    HeatMap(point,radius=radius).add_to(mp)\n",
    "    \n",
    "mp.save(outfile='casos_activos_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(tuple(zip(pointArrays, radio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}